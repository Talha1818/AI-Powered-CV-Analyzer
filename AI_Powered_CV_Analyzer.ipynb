{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install -q youtube-transcript-api langchain langchain-core langchain-community langchain-openai langchain-anthropic langchain-google-genai google-generativeai langchain-huggingface langchain-groq openai huggingface-hub transformers faiss-cpu tiktoken python-dotenv numpy scikit-learn grandalf sentence_transformers InstructorEmbedding pymupdf"
      ],
      "metadata": {
        "id": "wDoaqO1USCHS"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "import getpass\n",
        "import os\n",
        "from langchain_community.document_loaders import DirectoryLoader, PyMuPDFLoader\n",
        "from langchain.schema import Document"
      ],
      "metadata": {
        "id": "Zx0xtbk3Sf4y"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rulEbQ9XO1eI",
        "outputId": "94c035ff-6a63-40a3-f8be-294f1de2a02d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 10.64it/s]\n"
          ]
        }
      ],
      "source": [
        "# STEP 1: Collect all .pdf files using DirectoryLoader (doesn't load yet)\n",
        "directory_path = \"/content/drive/MyDrive/CV\"\n",
        "\n",
        "loader = DirectoryLoader(\n",
        "    path=directory_path,\n",
        "    glob=\"**/*.pdf\",\n",
        "    loader_cls=PyMuPDFLoader,\n",
        "    show_progress=True,\n",
        "    use_multithreading=True,\n",
        "\n",
        ")\n",
        "docs = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmuK9UsnTOCv",
        "outputId": "63c4ba38-aaba-4443-b18f-8575d8b87186"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc_sources = [doc.metadata[\"source\"] for doc in docs]\n",
        "doc_sources"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6n4acLGTO3L",
        "outputId": "b8f29c82-81ba-46b6-865b-e98a7e23bdb6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/CV/MuhammadTalhaCV1.pdf',\n",
              " '/content/drive/MyDrive/CV/Muhammad Talha - ML Engineer.pdf',\n",
              " '/content/drive/MyDrive/CV/Muhammad Talha - ML Engineer.pdf',\n",
              " '/content/drive/MyDrive/CV/Muhammad Talha - ML Engineer.pdf']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(docs[1].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GJ2RbTOTSEW",
        "outputId": "40695cd0-f895-48b4-eab4-eeea9e590c58"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N/A \n",
            " \n",
            "N/A \n",
            "Muhammad Talha \n",
            "Gujranwala, Punjab, Pakistan       \n",
            " muhammadtalha1818@gmail.com       \n",
            "+923444300394 \n",
            " \n",
            " https://www.linkedin.com/in/muhammad-talha-b643641b2/ \n",
            " https://github.com/Talha1818 \n",
            " \n",
            " \n",
            "  \n",
            "SUMMARY \n",
            "Highly experienced in the domains of machine learning, deep learning, and natural language processing (NLP), I am a \n",
            "passionate engineer and thriving analyst. With a strong aptitude for applying ML techniques and developing advanced \n",
            "algorithms, I excel in solving complex real-world problems. My profound interest lies in research, Artificial Intelligence, and \n",
            "robotics, as I continuously strive to explore innovative frontiers and contribute to advancements in these fields. \n",
            " \n",
            "EXPERIENCE \n",
            "Freelance | Upwork | San Francisco, CA | Feb 2024 - Present \n",
            "ï‚· \n",
            "A freelance specialist adept at delivering impactful solutions in machine learning and AI realms, specializing in NLP, \n",
            "LLMs, and generative AI technologies. From conceptualization to deployment, I craft tailored solutions utilizing \n",
            "advanced algorithms to tackle intricate problems and spark innovation in data analytics and AI applications. \n",
            "Machine Learning Engineer | TransData | Lahore, PK | October 2022 â€“ March 2024 \n",
            "ï‚· \n",
            "Contributed to the development and implementation of the \"Document Classifier\" at TransData, an advanced AI \n",
            "system for automating the classification of title closing documents in the mortgage and lending industry. \n",
            "ï‚· \n",
            "Leveraged AI technology, specifically BERT, to create a cutting-edge solution that increased productivity, reduced \n",
            "manual effort, minimized misclassification risks, and improved document management workflows. The machine \n",
            "learning models deployed achieved a prediction accuracy score of over 98%, significantly reducing end-to-end \n",
            "processing time. \n",
            "ï‚· \n",
            "Leveraged AWS Cloud services to enhance scalability and reliability, implementing a Title Docs AI system. Created an \n",
            "API using AWS Lambda and API Gateway to provide seamless integration and efficient communication between the \n",
            "application and the cloud infrastructure. \n",
            "Machine Learning Engineer | BLING | San Francisco, CA | September 2022 - March 2023 \n",
            "ï‚· \n",
            "At BLING, I played a key role in projects related to message spam detection and sentiment analysis. Additionally, I \n",
            "contributed to the development of a GPT-powered chatbot to improve user experiences by effectively filtering out \n",
            "spam, extracting sentiment insights, and providing accurate responses to user inquiries. \n",
            "ï‚· \n",
            "Moreover, we successfully handled API implementation on AWS, utilizing services such as AWS Lambda and API \n",
            "Gateway. This allowed seamless integration and efficient communication between our applications and the cloud \n",
            "infrastructure, ensuring robust and scalable performance. \n",
            "Machine Learning Engineer | HAWKLOGIX | Lahore, PK | February 2022 - August 2022 \n",
            "ï‚· \n",
            "At HAWKLOGIX, I worked on the TeleStroke evaluation project aimed at improving the hospital's response time to \n",
            "emergency stroke care and enhancing patient outcomes. My responsibilities can be summarized as follows: \n",
            "ï‚· \n",
            "Conducted thorough data analysis to identify hours with a higher ratio of blasts in comparison to other periods. This \n",
            "analysis helped in pinpointing the critical timeframes that required immediate attention. \n",
            "ï‚· \n",
            "Developed an AI system utilizing Machine Learning techniques to predict the probability of blasts occurring within \n",
            "specific time periods. This system provided valuable insights into the likelihood of stroke emergencies. \n",
            "ï‚· \n",
            "Utilized the AI system's output to effectively allocate resources, including doctors and medical staff, during the \n",
            "identified timeframes with higher blast probabilities. This strategic resource management approach optimized \n",
            "response times and minimized costs. \n",
            "Machine Learning Engineer | Fiver | San Francisco, CA | November 2020 - January 2022 \n",
            "ï‚· \n",
            "Successfully completed diverse freelance projects encompassing Machine Learning, Deep Learning, and NLP, \n",
            "involving tasks such as Classification, Regression, CNN, and Transfer Learning. \n",
            "ï‚· \n",
            "Leveraged powerful tools and libraries like TensorFlow, Keras, and scikit-learn to develop and experiment with \n",
            "various models, ensuring thorough research and effective development. \n",
            "ï‚· \n",
            "Proficiency in web application development using Django and Flask frameworks, enabling the creation of \n",
            "comprehensive solutions that seamlessly integrate machine learning capabilities into web-based platforms.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "from langchain.schema import Document\n",
        "\n",
        "# Step 1: Group all text chunks by source\n",
        "combined_texts = defaultdict(str)\n",
        "\n",
        "for doc in docs:\n",
        "    source = doc.metadata.get(\"source\", \"unknown\")\n",
        "    combined_texts[source] += doc.page_content.strip() + \"\\n\"\n",
        "\n",
        "# Step 2: Recreate Document objects, one per source\n",
        "merged_docs = [\n",
        "    Document(page_content=text, metadata={\"source\": source})\n",
        "    for source, text in combined_texts.items()\n",
        "]\n",
        "\n",
        "print(f\"âœ… Merged documents count: {len(merged_docs)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deKZHEpLXDYV",
        "outputId": "ae8a7d75-9844-417d-c2ae-3f149cd7ebe3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Merged documents count: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(merged_docs[1].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4t2ZDjJ1XdkJ",
        "outputId": "6ef55f1a-5f2c-4b03-9a6d-7c25342a20a7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N/A \n",
            " \n",
            "N/A \n",
            "Muhammad Talha \n",
            "Gujranwala, Punjab, Pakistan       \n",
            " muhammadtalha1818@gmail.com       \n",
            "+923444300394 \n",
            " \n",
            " https://www.linkedin.com/in/muhammad-talha-b643641b2/ \n",
            " https://github.com/Talha1818 \n",
            " \n",
            " \n",
            "  \n",
            "SUMMARY \n",
            "Highly experienced in the domains of machine learning, deep learning, and natural language processing (NLP), I am a \n",
            "passionate engineer and thriving analyst. With a strong aptitude for applying ML techniques and developing advanced \n",
            "algorithms, I excel in solving complex real-world problems. My profound interest lies in research, Artificial Intelligence, and \n",
            "robotics, as I continuously strive to explore innovative frontiers and contribute to advancements in these fields. \n",
            " \n",
            "EXPERIENCE \n",
            "Freelance | Upwork | San Francisco, CA | Feb 2024 - Present \n",
            "ï‚· \n",
            "A freelance specialist adept at delivering impactful solutions in machine learning and AI realms, specializing in NLP, \n",
            "LLMs, and generative AI technologies. From conceptualization to deployment, I craft tailored solutions utilizing \n",
            "advanced algorithms to tackle intricate problems and spark innovation in data analytics and AI applications. \n",
            "Machine Learning Engineer | TransData | Lahore, PK | October 2022 â€“ March 2024 \n",
            "ï‚· \n",
            "Contributed to the development and implementation of the \"Document Classifier\" at TransData, an advanced AI \n",
            "system for automating the classification of title closing documents in the mortgage and lending industry. \n",
            "ï‚· \n",
            "Leveraged AI technology, specifically BERT, to create a cutting-edge solution that increased productivity, reduced \n",
            "manual effort, minimized misclassification risks, and improved document management workflows. The machine \n",
            "learning models deployed achieved a prediction accuracy score of over 98%, significantly reducing end-to-end \n",
            "processing time. \n",
            "ï‚· \n",
            "Leveraged AWS Cloud services to enhance scalability and reliability, implementing a Title Docs AI system. Created an \n",
            "API using AWS Lambda and API Gateway to provide seamless integration and efficient communication between the \n",
            "application and the cloud infrastructure. \n",
            "Machine Learning Engineer | BLING | San Francisco, CA | September 2022 - March 2023 \n",
            "ï‚· \n",
            "At BLING, I played a key role in projects related to message spam detection and sentiment analysis. Additionally, I \n",
            "contributed to the development of a GPT-powered chatbot to improve user experiences by effectively filtering out \n",
            "spam, extracting sentiment insights, and providing accurate responses to user inquiries. \n",
            "ï‚· \n",
            "Moreover, we successfully handled API implementation on AWS, utilizing services such as AWS Lambda and API \n",
            "Gateway. This allowed seamless integration and efficient communication between our applications and the cloud \n",
            "infrastructure, ensuring robust and scalable performance. \n",
            "Machine Learning Engineer | HAWKLOGIX | Lahore, PK | February 2022 - August 2022 \n",
            "ï‚· \n",
            "At HAWKLOGIX, I worked on the TeleStroke evaluation project aimed at improving the hospital's response time to \n",
            "emergency stroke care and enhancing patient outcomes. My responsibilities can be summarized as follows: \n",
            "ï‚· \n",
            "Conducted thorough data analysis to identify hours with a higher ratio of blasts in comparison to other periods. This \n",
            "analysis helped in pinpointing the critical timeframes that required immediate attention. \n",
            "ï‚· \n",
            "Developed an AI system utilizing Machine Learning techniques to predict the probability of blasts occurring within \n",
            "specific time periods. This system provided valuable insights into the likelihood of stroke emergencies. \n",
            "ï‚· \n",
            "Utilized the AI system's output to effectively allocate resources, including doctors and medical staff, during the \n",
            "identified timeframes with higher blast probabilities. This strategic resource management approach optimized \n",
            "response times and minimized costs. \n",
            "Machine Learning Engineer | Fiver | San Francisco, CA | November 2020 - January 2022 \n",
            "ï‚· \n",
            "Successfully completed diverse freelance projects encompassing Machine Learning, Deep Learning, and NLP, \n",
            "involving tasks such as Classification, Regression, CNN, and Transfer Learning. \n",
            "ï‚· \n",
            "Leveraged powerful tools and libraries like TensorFlow, Keras, and scikit-learn to develop and experiment with \n",
            "various models, ensuring thorough research and effective development. \n",
            "ï‚· \n",
            "Proficiency in web application development using Django and Flask frameworks, enabling the creation of \n",
            "comprehensive solutions that seamlessly integrate machine learning capabilities into web-based platforms.\n",
            "N/A \n",
            " \n",
            " \n",
            "PROJECTS \n",
            "FYP â€“ Mobile Application for Blind Person Navigate through Voice Message \n",
            "ï‚· \n",
            "Developed a mobile application as a Final Year Project (FYP) to assist blind individuals in navigating through voice \n",
            "messages. \n",
            "ï‚· \n",
            "Leveraged the TensorFlow Lite API as a crucial tool for integrating the model with the mobile interface, \n",
            "enabling seamless communication. \n",
            "ï‚· \n",
            "Employed transfer learning techniques and trained the model on custom data, achieving an impressive accuracy rate \n",
            "of 96%. \n",
            "Research on Heart failure clinical records Data Set \n",
            "ï‚· \n",
            "Conducted research on a Heart Failure clinical records dataset to investigate the importance of features using \n",
            "various statistical tests, aiming to gain insights into predictive factors for heart failure. \n",
            "ï‚· \n",
            "Implemented machine learning models to improve the accuracy of heart failure prediction, successfully achieving a \n",
            "significant improvement of 4% (97%) accuracy compared to previous models. This enhanced accuracy can contribute \n",
            "to more effective identification and management of heart failure cases. \n",
            "AI Title Docs \n",
            "ï‚· \n",
            "The \"Document Classifier\" automates the classification of title closing documents using the BERT model, \n",
            "improving efficiency and accuracy in document processing. \n",
            "ï‚· \n",
            "The implementation of the AI-based system with a full pipeline through SageMaker, Lambda, and API Gateway offers \n",
            "a comprehensive solution that enhances productivity, reduces manual effort, and minimizes misclassification risks in \n",
            "mortgage and lending processes. \n",
            "ï‚· \n",
            "Powered by BERT, the Document Classifier sets new industry standards by enabling smoother workflows, \n",
            "seamless integration, and advanced document management in the mortgage and lending sector. \n",
            "GPT Training on Text Data for Advanced NLP Generation & Analysis \n",
            "ï‚· \n",
            "Conducted GPT training on text data using Hugging Face, a leading library for natural language processing (NLP) \n",
            "tasks. \n",
            "ï‚· \n",
            "Leveraged Hugging Face's tools and models to train the GPT model on large-scale text datasets, enabling \n",
            "advanced natural language generation and analysis. \n",
            "ï‚· \n",
            "Explored various techniques and approaches within Hugging Face to optimize the GPT model's performance for \n",
            "tasks such as text generation. \n",
            " \n",
            "CERTIFICATIONS \n",
            "Structured Query Language (SQL) | HackerRank | 2022 \n",
            "The SQL certificate is relevant as it demonstrates proficiency in database management and querying skills, essential for roles in \n",
            "data analysis, database administration, and software development. \n",
            "Pandas | Kaggle | 2021 \n",
            "The Pandas certificate is relevant as it validates expertise in utilizing the powerful Pandas library for effective data \n",
            "manipulation and analysis, a crucial skill in data analysis and data science. \n",
            "Certified Data Scientist | Professional Freelancing Training Program | 2021 \n",
            "The Certified Data Scientist certificate validates advanced skills in data science, including data preprocessing, machine \n",
            "learning, and statistical analysis, making it valuable for pursuing data-driven career opportunities. \n",
            "Artificial Intelligence | Professional Freelancing Training Program | 2021 \n",
            "The Artificial Intelligence certificate validates specialized knowledge and skills in AI, including algorithm design and \n",
            "implementation, machine learning, and deep learning, enhancing career prospects in AI research, development, and \n",
            "application. \n",
            "Introduction to Programming Using Python | HackerRank | 2020 \n",
            "The certificate in \"Introduction to Programming Using Python\" validates foundational programming knowledge and \n",
            "proficiency in Python, essential for entry-level programming roles and further studies in programming.\n",
            "N/A \n",
            " \n",
            "N/A \n",
            " \n",
            "EDUCATION \n",
            "Bachelor of Software Engineering | Minor in Data Science, Web Development, HCI | National Textile \n",
            "University | Faisalabad, PK | 2021 | 3.52 \n",
            "F.Sc. Pre-Engineering | Minor in Mathematics | Army Public School & College | Gujranwala \n",
            "Cantt | 2016 | 75% \n",
            " \n",
            " \n",
            "SKILLS \n",
            "Machine Learning: sci-kit-learn, TensorFlow, PyTorch \n",
            "Data Analysis: Pandas, NumPy, SciPy, matplotlib, seaborn, Plotly  \n",
            "Deep Learning: TensorFlow, PyTorch \n",
            "Computer Vision: OpenCV \n",
            "Natural Language Processing (NLP): NLTK, spaCy, Gensim \n",
            "Web Development: Flask, Django \n",
            "Desktop Application: Tkinter \n",
            "MLops: AWS EC2, AWS Elastic Beanstalk, AWS Lambda, SageMaker, API Gateway\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings  = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "vector_store = FAISS.from_documents(merged_docs, embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tcqnr3D4YIjH",
        "outputId": "c138c10a-1bd4-4c1d-acfe-0537a96789a8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-9-3114161211.py:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embeddings  = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Run a sample query\n",
        "query = \"Python developer with experience in machine learning and NLP\"\n",
        "docs_with_scores = vector_store.similarity_search_with_score(query)\n",
        "\n",
        "\n",
        "# Step 2: Convert distance to similarity score\n",
        "def distance_to_score(distance: float) -> float:\n",
        "    \"\"\"Convert L2 distance to a normalized similarity score (0â€“100%)\"\"\"\n",
        "    similarity = 1 / (1 + distance)         # Normalized between 0 and 1\n",
        "    return round(similarity * 100, 2)       # As percentage\n",
        "\n",
        "def get_score(docs_with_scores, query):\n",
        "  # Step 3: Display results with scores\n",
        "  for i, (doc, distance) in enumerate(docs_with_scores):\n",
        "      score_percent = distance_to_score(distance)\n",
        "      print(f\"\\nðŸ”¹ Match #{i+1} â€” Score %: {score_percent}% â€” Score: {distance}\")\n",
        "      print(f\"ðŸ“ Source: {doc.metadata.get('source', 'unknown')}\")\n",
        "      # print(f\"ðŸ“„ Snippet:\\n{doc.page_content[:300]}...\\n\")\n",
        "\n",
        "get_score(docs_with_scores, query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9N0Snt-wYSGB",
        "outputId": "444eae68-4fd2-440f-9bce-f5f2ed0024aa"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ”¹ Match #1 â€” Score %: 52.220001220703125% â€” Score: 0.9150180816650391\n",
            "ðŸ“ Source: /content/drive/MyDrive/CV/MuhammadTalhaCV1.pdf\n",
            "\n",
            "ðŸ”¹ Match #2 â€” Score %: 52.20000076293945% â€” Score: 0.9156745672225952\n",
            "ðŸ“ Source: /content/drive/MyDrive/CV/Muhammad Talha - ML Engineer.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in vector_store.similarity_search_with_relevance_scores(\"Python developer with experience in machine learning and NLP\"):\n",
        "  # print(i[0].metadata['score_percent'])\n",
        "  print(i)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwTwcPUIffX8",
        "outputId": "8a7fd72e-1ec4-4976-ac5f-97060437821a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Document(id='d70038b0-7891-4eeb-b625-49802834d348', metadata={'source': '/content/drive/MyDrive/CV/MuhammadTalhaCV1.pdf'}, page_content='Muhammad Talha \\nSOFTWARE ENGINEER \\nCAREER \\nIâ€™m a software engineer and 1 year \\nexperience in python language from \\nfreelancing to handle any task in \\npython and Machine Learning based \\nprojects. \\nInterested in research ,  \\nArtificial Intelligence  \\nand Robotics . \\n \\nCONTACT \\n+923444300394 \\nmuhammadtalha1818@gmail.com \\nNational Textile University Faisalbd \\nINTEREST \\nEDUCATION \\nSKILLS AND ABILITIES \\nPERSONAL SKILLS \\nBachelor of Computer Science \\n Oct 2017 present \\n National Textile University Faisalabaad \\nHigh School \\n March 2012 - March 2016 \\nArmy Public School & College GWA CANTT \\nThe following are my best skills which I believe are \\napplicable to the position I have applied for: \\n1. Programming \\n2. Logical and Structured Thinking \\n3. Coding in Multiple Languages (Python, Java, C++ etc) \\n1. Ability to work by myself without the need for \\n    constant supervision by employees. \\n2. Able to work harmoniously with other members \\n    of the team. \\n3. Possesses great analytical and problem solving skills. \\nPROJECTS \\n1. JARVIS Voice Assistant AI (Python) \\n2. Blood Donation Society Desktop App (Python TKINTER) \\n3. Stationary Management System Desktop App (Python) \\n4. Performing Analysis of Meteorological Data (Python ML) \\n5. Recognizing Handwritten Digits with scikit-learn \\n(Python) \\nOther â€¦ \\n \\nGITHUB - \\nhttps://github.com/Talha1818?tab=repositories \\nBLOG - \\nhttps://medium.com/me/stories/public\\n'), np.float32(0.3529845))\n",
            "(Document(id='10c6b70f-2615-4748-8700-d72a752a899d', metadata={'source': '/content/drive/MyDrive/CV/Muhammad Talha - ML Engineer.pdf'}, page_content='N/A \\n \\nN/A \\nMuhammad Talha \\nGujranwala, Punjab, Pakistan       \\n muhammadtalha1818@gmail.com       \\n+923444300394 \\n \\n https://www.linkedin.com/in/muhammad-talha-b643641b2/ \\n https://github.com/Talha1818 \\n \\n \\n  \\nSUMMARY \\nHighly experienced in the domains of machine learning, deep learning, and natural language processing (NLP), I am a \\npassionate engineer and thriving analyst. With a strong aptitude for applying ML techniques and developing advanced \\nalgorithms, I excel in solving complex real-world problems. My profound interest lies in research, Artificial Intelligence, and \\nrobotics, as I continuously strive to explore innovative frontiers and contribute to advancements in these fields. \\n \\nEXPERIENCE \\nFreelance | Upwork | San Francisco, CA | Feb 2024 - Present \\n\\uf0b7 \\nA freelance specialist adept at delivering impactful solutions in machine learning and AI realms, specializing in NLP, \\nLLMs, and generative AI technologies. From conceptualization to deployment, I craft tailored solutions utilizing \\nadvanced algorithms to tackle intricate problems and spark innovation in data analytics and AI applications. \\nMachine Learning Engineer | TransData | Lahore, PK | October 2022 â€“ March 2024 \\n\\uf0b7 \\nContributed to the development and implementation of the \"Document Classifier\" at TransData, an advanced AI \\nsystem for automating the classification of title closing documents in the mortgage and lending industry. \\n\\uf0b7 \\nLeveraged AI technology, specifically BERT, to create a cutting-edge solution that increased productivity, reduced \\nmanual effort, minimized misclassification risks, and improved document management workflows. The machine \\nlearning models deployed achieved a prediction accuracy score of over 98%, significantly reducing end-to-end \\nprocessing time. \\n\\uf0b7 \\nLeveraged AWS Cloud services to enhance scalability and reliability, implementing a Title Docs AI system. Created an \\nAPI using AWS Lambda and API Gateway to provide seamless integration and efficient communication between the \\napplication and the cloud infrastructure. \\nMachine Learning Engineer | BLING | San Francisco, CA | September 2022 - March 2023 \\n\\uf0b7 \\nAt BLING, I played a key role in projects related to message spam detection and sentiment analysis. Additionally, I \\ncontributed to the development of a GPT-powered chatbot to improve user experiences by effectively filtering out \\nspam, extracting sentiment insights, and providing accurate responses to user inquiries. \\n\\uf0b7 \\nMoreover, we successfully handled API implementation on AWS, utilizing services such as AWS Lambda and API \\nGateway. This allowed seamless integration and efficient communication between our applications and the cloud \\ninfrastructure, ensuring robust and scalable performance. \\nMachine Learning Engineer | HAWKLOGIX | Lahore, PK | February 2022 - August 2022 \\n\\uf0b7 \\nAt HAWKLOGIX, I worked on the TeleStroke evaluation project aimed at improving the hospital\\'s response time to \\nemergency stroke care and enhancing patient outcomes. My responsibilities can be summarized as follows: \\n\\uf0b7 \\nConducted thorough data analysis to identify hours with a higher ratio of blasts in comparison to other periods. This \\nanalysis helped in pinpointing the critical timeframes that required immediate attention. \\n\\uf0b7 \\nDeveloped an AI system utilizing Machine Learning techniques to predict the probability of blasts occurring within \\nspecific time periods. This system provided valuable insights into the likelihood of stroke emergencies. \\n\\uf0b7 \\nUtilized the AI system\\'s output to effectively allocate resources, including doctors and medical staff, during the \\nidentified timeframes with higher blast probabilities. This strategic resource management approach optimized \\nresponse times and minimized costs. \\nMachine Learning Engineer | Fiver | San Francisco, CA | November 2020 - January 2022 \\n\\uf0b7 \\nSuccessfully completed diverse freelance projects encompassing Machine Learning, Deep Learning, and NLP, \\ninvolving tasks such as Classification, Regression, CNN, and Transfer Learning. \\n\\uf0b7 \\nLeveraged powerful tools and libraries like TensorFlow, Keras, and scikit-learn to develop and experiment with \\nvarious models, ensuring thorough research and effective development. \\n\\uf0b7 \\nProficiency in web application development using Django and Flask frameworks, enabling the creation of \\ncomprehensive solutions that seamlessly integrate machine learning capabilities into web-based platforms.\\nN/A \\n \\n \\nPROJECTS \\nFYP â€“ Mobile Application for Blind Person Navigate through Voice Message \\n\\uf0b7 \\nDeveloped a mobile application as a Final Year Project (FYP) to assist blind individuals in navigating through voice \\nmessages. \\n\\uf0b7 \\nLeveraged the TensorFlow Lite API as a crucial tool for integrating the model with the mobile interface, \\nenabling seamless communication. \\n\\uf0b7 \\nEmployed transfer learning techniques and trained the model on custom data, achieving an impressive accuracy rate \\nof 96%. \\nResearch on Heart failure clinical records Data Set \\n\\uf0b7 \\nConducted research on a Heart Failure clinical records dataset to investigate the importance of features using \\nvarious statistical tests, aiming to gain insights into predictive factors for heart failure. \\n\\uf0b7 \\nImplemented machine learning models to improve the accuracy of heart failure prediction, successfully achieving a \\nsignificant improvement of 4% (97%) accuracy compared to previous models. This enhanced accuracy can contribute \\nto more effective identification and management of heart failure cases. \\nAI Title Docs \\n\\uf0b7 \\nThe \"Document Classifier\" automates the classification of title closing documents using the BERT model, \\nimproving efficiency and accuracy in document processing. \\n\\uf0b7 \\nThe implementation of the AI-based system with a full pipeline through SageMaker, Lambda, and API Gateway offers \\na comprehensive solution that enhances productivity, reduces manual effort, and minimizes misclassification risks in \\nmortgage and lending processes. \\n\\uf0b7 \\nPowered by BERT, the Document Classifier sets new industry standards by enabling smoother workflows, \\nseamless integration, and advanced document management in the mortgage and lending sector. \\nGPT Training on Text Data for Advanced NLP Generation & Analysis \\n\\uf0b7 \\nConducted GPT training on text data using Hugging Face, a leading library for natural language processing (NLP) \\ntasks. \\n\\uf0b7 \\nLeveraged Hugging Face\\'s tools and models to train the GPT model on large-scale text datasets, enabling \\nadvanced natural language generation and analysis. \\n\\uf0b7 \\nExplored various techniques and approaches within Hugging Face to optimize the GPT model\\'s performance for \\ntasks such as text generation. \\n \\nCERTIFICATIONS \\nStructured Query Language (SQL) | HackerRank | 2022 \\nThe SQL certificate is relevant as it demonstrates proficiency in database management and querying skills, essential for roles in \\ndata analysis, database administration, and software development. \\nPandas | Kaggle | 2021 \\nThe Pandas certificate is relevant as it validates expertise in utilizing the powerful Pandas library for effective data \\nmanipulation and analysis, a crucial skill in data analysis and data science. \\nCertified Data Scientist | Professional Freelancing Training Program | 2021 \\nThe Certified Data Scientist certificate validates advanced skills in data science, including data preprocessing, machine \\nlearning, and statistical analysis, making it valuable for pursuing data-driven career opportunities. \\nArtificial Intelligence | Professional Freelancing Training Program | 2021 \\nThe Artificial Intelligence certificate validates specialized knowledge and skills in AI, including algorithm design and \\nimplementation, machine learning, and deep learning, enhancing career prospects in AI research, development, and \\napplication. \\nIntroduction to Programming Using Python | HackerRank | 2020 \\nThe certificate in \"Introduction to Programming Using Python\" validates foundational programming knowledge and \\nproficiency in Python, essential for entry-level programming roles and further studies in programming.\\nN/A \\n \\nN/A \\n \\nEDUCATION \\nBachelor of Software Engineering | Minor in Data Science, Web Development, HCI | National Textile \\nUniversity | Faisalabad, PK | 2021 | 3.52 \\nF.Sc. Pre-Engineering | Minor in Mathematics | Army Public School & College | Gujranwala \\nCantt | 2016 | 75% \\n \\n \\nSKILLS \\nMachine Learning: sci-kit-learn, TensorFlow, PyTorch \\nData Analysis: Pandas, NumPy, SciPy, matplotlib, seaborn, Plotly  \\nDeep Learning: TensorFlow, PyTorch \\nComputer Vision: OpenCV \\nNatural Language Processing (NLP): NLTK, spaCy, Gensim \\nWeb Development: Flask, Django \\nDesktop Application: Tkinter \\nMLops: AWS EC2, AWS Elastic Beanstalk, AWS Lambda, SageMaker, API Gateway\\n'), np.float32(0.3525203))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Run your query\n",
        "query = \"need a developer that can work in JAVA, react native\"\n",
        "docs_with_scores = vector_store.similarity_search_with_score(query)\n",
        "\n",
        "get_score(docs_with_scores, query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6H7leNABdI-r",
        "outputId": "6c056ed3-0fb7-4dfc-8512-a80776d8a4cf"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ”¹ Match #1 â€” Score %: 40.130001068115234% â€” Score: 1.491804599761963\n",
            "ðŸ“ Source: /content/drive/MyDrive/CV/MuhammadTalhaCV1.pdf\n",
            "\n",
            "ðŸ”¹ Match #2 â€” Score %: 38.79999923706055% â€” Score: 1.5776329040527344\n",
            "ðŸ“ Source: /content/drive/MyDrive/CV/Muhammad Talha - ML Engineer.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Run your query\n",
        "query = \"We are seeking a skilled Python Developer with experience in machine learning, natural language processing (NLP), deep learning, and cloud platforms like AWS. The ideal candidate will have a strong background in building and deploying ML models, working with NLP frameworks (e.g., HuggingFace, spaCy), and developing scalable solutions using Python. Experience with AWS services such as SageMaker or Lambda is a plus. Youâ€™ll work closely with a cross-functional team to design, develop, and deploy intelligent systems that process and analyze unstructured data at scale.\"\n",
        "docs_with_scores = vector_store.similarity_search_with_score(query)\n",
        "\n",
        "get_score(docs_with_scores, query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwliHRgEguek",
        "outputId": "fcdbd498-960a-4b31-b21d-393ce20fc0c3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ”¹ Match #1 â€” Score %: 53.20000076293945% â€” Score: 0.8797935843467712\n",
            "ðŸ“ Source: /content/drive/MyDrive/CV/Muhammad Talha - ML Engineer.pdf\n",
            "\n",
            "ðŸ”¹ Match #2 â€” Score %: 50.869998931884766% â€” Score: 0.9657047986984253\n",
            "ðŸ“ Source: /content/drive/MyDrive/CV/MuhammadTalhaCV1.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "from langchain_core.runnables import chain\n",
        "\n",
        "@chain\n",
        "def __retriever(query: str) -> List[Document]:\n",
        "    docs, scores = zip(*vector_store.similarity_search_with_score(query))\n",
        "    for doc, score in zip(docs, scores):\n",
        "        doc.metadata[\"score\"] = score\n",
        "\n",
        "    return docs"
      ],
      "metadata": {
        "id": "Xut8GxvHaMAe"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = __retriever.invoke(\"need a developer that can work in JAVA, react native\")\n",
        "for doc in retriever:\n",
        "    print(f\"Score: {doc.metadata['score']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a86UUwrGby6k",
        "outputId": "1810ea57-1f77-4f2f-8ff5-fa28cf0e3bf3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: 1.491804599761963\n",
            "Score: 1.5776329040527344\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "\n",
        "retriever_chain = RunnableLambda(\n",
        "    lambda query: [\n",
        "        _add_score_to_doc(doc, score)\n",
        "        for doc, score in vector_store.similarity_search_with_score(query)\n",
        "    ]\n",
        ")\n",
        "\n",
        "def _add_score_to_doc(doc: Document, score: float) -> Document:\n",
        "    score_percent = distance_to_score(score)\n",
        "    doc.metadata[\"score_percent\"] = score_percent\n",
        "    doc.metadata[\"distance\"] = score\n",
        "    return doc\n",
        "\n",
        "retriever = retriever_chain.invoke(\"need a developer that can work in JAVA, react native\")\n",
        "for doc in retriever:\n",
        "    print(f\"Score: {doc.metadata['distance'], doc.metadata['score_percent']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuTYGKzniNh0",
        "outputId": "3939e46c-8f20-4ee5-f6dc-56ffe4bafbac"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: (np.float32(1.4918046), np.float32(40.13))\n",
            "Score: (np.float32(1.5776329), np.float32(38.8))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def label_score_by_distance(distance: float) -> str:\n",
        "    if distance <= 0.8:\n",
        "        return \"Strong match\"\n",
        "    elif distance <= 1.2:\n",
        "        return \"Moderate match\"\n",
        "    else:\n",
        "        return \"Weak match\""
      ],
      "metadata": {
        "id": "YmLZEWOTb3hj"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"GROQ_API_KEY\"] = getpass.getpass()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0nTG_7ejUFj",
        "outputId": "3ad898da-9791-4ba8-e0f7-4074c7c50c2d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGroq(temperature = 0, model=\"llama3-8b-8192\")"
      ],
      "metadata": {
        "id": "1WilnDOevdO9"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    template=\"\"\"\n",
        "You are a smart and precise Resume Analyzer.\n",
        "\n",
        "You are given a **Job Description** and a candidate's **Resume** (in plain text format).\n",
        "Your task is to analyze how well the resume matches the job requirements and return a detailed, structured report.\n",
        "\n",
        "ðŸ”¹ ONLY use the resume content for your answers.\n",
        "ðŸ”¹ If any information is missing from the resume, write \"Not Found\".\n",
        "\n",
        "---\n",
        "\n",
        "ðŸ“„ **Job Description**:\n",
        "{job_description}\n",
        "\n",
        "ðŸ“ƒ **Resume**:\n",
        "{resume}\n",
        "\n",
        "---\n",
        "\n",
        "âœï¸ Now generate the following structured report:\n",
        "\n",
        "1. âœ… **Match Score (0â€“100%)** â€” Based on skills, experience, education relevance.\n",
        "2. ðŸŽ“ **Education** â€” Summarize degree(s), institution(s), and relevant fields.\n",
        "3. ðŸ’¼ **Experience** â€” Summarize past job roles, companies, and durations.\n",
        "4. ðŸ› ï¸ **Skills / Strengths** â€” Extract technical and soft skills.\n",
        "5. â¸ï¸ **Employment Gaps** â€” If any, mention time periods and durations.\n",
        "6. ðŸ“ž **Contact Info** â€” Extract email, phone number, LinkedIn (if available).\n",
        "7. ðŸ“ **Summary** â€” Short paragraph on how well this candidate fits the job.\n",
        "\n",
        "Only output the report â€” do not provide explanations or repeat the resume/job description.\n",
        "\"\"\",\n",
        "    input_variables=[\"job_description\", \"resume\"]\n",
        ")\n"
      ],
      "metadata": {
        "id": "bcqId2dBjeQ4"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "job_description = '''\n",
        "ðŸ§‘â€ðŸ’¼ Job Title: Data Scientist\n",
        "We are seeking a Data Scientist with a strong foundation in data analysis, machine learning, and statistical modeling. The ideal candidate will be responsible for extracting insights from complex datasets, building predictive models, and communicating findings that drive business decisions.\n",
        "\n",
        "Key Responsibilities\n",
        "Analyze large datasets to discover trends, patterns, and actionable insights.\n",
        "\n",
        "Build and deploy machine learning models for classification, regression, and clustering tasks.\n",
        "\n",
        "Collaborate with engineering teams to integrate models into production systems.\n",
        "\n",
        "Use tools like Python, SQL, Pandas, and Scikit-learn for data processing and modeling.\n",
        "\n",
        "Communicate results clearly to both technical and non-technical stakeholders.\n",
        "\n",
        "Qualifications\n",
        "Proficiency in Python, SQL, and ML frameworks (e.g., Scikit-learn, TensorFlow).\n",
        "\n",
        "Strong background in statistics, data wrangling, and visualization.\n",
        "\n",
        "Hands-on experience with data science projects, including model evaluation and tuning.\n",
        "\n",
        "Experience with data tools (Jupyter, Airflow, Tableau) and cloud platforms (AWS/GCP).\n",
        "'''"
      ],
      "metadata": {
        "id": "okWlZZGrj6Fj"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = retriever_chain.invoke(job_description)\n",
        "for doc in retriever:\n",
        "    print(f\"Score: {doc.metadata['distance'], doc.metadata['score_percent']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7PD6BTCkaDu",
        "outputId": "3ffee9bc-c877-43f7-d6c4-92e4406a38c9"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: (np.float32(0.7844763), np.float32(56.04))\n",
            "Score: (np.float32(0.83004117), np.float32(54.64))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yliyhrn_miEM",
        "outputId": "ca89afce-569a-4540-bbe4-7cdd702f0358"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(id='d70038b0-7891-4eeb-b625-49802834d348', metadata={'source': '/content/drive/MyDrive/CV/MuhammadTalhaCV1.pdf', 'score': np.float32(1.4918046), 'score_percent': np.float32(56.04), 'distance': np.float32(0.7844763)}, page_content='Muhammad Talha \\nSOFTWARE ENGINEER \\nCAREER \\nIâ€™m a software engineer and 1 year \\nexperience in python language from \\nfreelancing to handle any task in \\npython and Machine Learning based \\nprojects. \\nInterested in research ,  \\nArtificial Intelligence  \\nand Robotics . \\n \\nCONTACT \\n+923444300394 \\nmuhammadtalha1818@gmail.com \\nNational Textile University Faisalbd \\nINTEREST \\nEDUCATION \\nSKILLS AND ABILITIES \\nPERSONAL SKILLS \\nBachelor of Computer Science \\n Oct 2017 present \\n National Textile University Faisalabaad \\nHigh School \\n March 2012 - March 2016 \\nArmy Public School & College GWA CANTT \\nThe following are my best skills which I believe are \\napplicable to the position I have applied for: \\n1. Programming \\n2. Logical and Structured Thinking \\n3. Coding in Multiple Languages (Python, Java, C++ etc) \\n1. Ability to work by myself without the need for \\n    constant supervision by employees. \\n2. Able to work harmoniously with other members \\n    of the team. \\n3. Possesses great analytical and problem solving skills. \\nPROJECTS \\n1. JARVIS Voice Assistant AI (Python) \\n2. Blood Donation Society Desktop App (Python TKINTER) \\n3. Stationary Management System Desktop App (Python) \\n4. Performing Analysis of Meteorological Data (Python ML) \\n5. Recognizing Handwritten Digits with scikit-learn \\n(Python) \\nOther â€¦ \\n \\nGITHUB - \\nhttps://github.com/Talha1818?tab=repositories \\nBLOG - \\nhttps://medium.com/me/stories/public\\n'),\n",
              " Document(id='10c6b70f-2615-4748-8700-d72a752a899d', metadata={'source': '/content/drive/MyDrive/CV/Muhammad Talha - ML Engineer.pdf', 'score': np.float32(1.5776329), 'score_percent': np.float32(54.64), 'distance': np.float32(0.83004117)}, page_content='N/A \\n \\nN/A \\nMuhammad Talha \\nGujranwala, Punjab, Pakistan       \\n muhammadtalha1818@gmail.com       \\n+923444300394 \\n \\n https://www.linkedin.com/in/muhammad-talha-b643641b2/ \\n https://github.com/Talha1818 \\n \\n \\n  \\nSUMMARY \\nHighly experienced in the domains of machine learning, deep learning, and natural language processing (NLP), I am a \\npassionate engineer and thriving analyst. With a strong aptitude for applying ML techniques and developing advanced \\nalgorithms, I excel in solving complex real-world problems. My profound interest lies in research, Artificial Intelligence, and \\nrobotics, as I continuously strive to explore innovative frontiers and contribute to advancements in these fields. \\n \\nEXPERIENCE \\nFreelance | Upwork | San Francisco, CA | Feb 2024 - Present \\n\\uf0b7 \\nA freelance specialist adept at delivering impactful solutions in machine learning and AI realms, specializing in NLP, \\nLLMs, and generative AI technologies. From conceptualization to deployment, I craft tailored solutions utilizing \\nadvanced algorithms to tackle intricate problems and spark innovation in data analytics and AI applications. \\nMachine Learning Engineer | TransData | Lahore, PK | October 2022 â€“ March 2024 \\n\\uf0b7 \\nContributed to the development and implementation of the \"Document Classifier\" at TransData, an advanced AI \\nsystem for automating the classification of title closing documents in the mortgage and lending industry. \\n\\uf0b7 \\nLeveraged AI technology, specifically BERT, to create a cutting-edge solution that increased productivity, reduced \\nmanual effort, minimized misclassification risks, and improved document management workflows. The machine \\nlearning models deployed achieved a prediction accuracy score of over 98%, significantly reducing end-to-end \\nprocessing time. \\n\\uf0b7 \\nLeveraged AWS Cloud services to enhance scalability and reliability, implementing a Title Docs AI system. Created an \\nAPI using AWS Lambda and API Gateway to provide seamless integration and efficient communication between the \\napplication and the cloud infrastructure. \\nMachine Learning Engineer | BLING | San Francisco, CA | September 2022 - March 2023 \\n\\uf0b7 \\nAt BLING, I played a key role in projects related to message spam detection and sentiment analysis. Additionally, I \\ncontributed to the development of a GPT-powered chatbot to improve user experiences by effectively filtering out \\nspam, extracting sentiment insights, and providing accurate responses to user inquiries. \\n\\uf0b7 \\nMoreover, we successfully handled API implementation on AWS, utilizing services such as AWS Lambda and API \\nGateway. This allowed seamless integration and efficient communication between our applications and the cloud \\ninfrastructure, ensuring robust and scalable performance. \\nMachine Learning Engineer | HAWKLOGIX | Lahore, PK | February 2022 - August 2022 \\n\\uf0b7 \\nAt HAWKLOGIX, I worked on the TeleStroke evaluation project aimed at improving the hospital\\'s response time to \\nemergency stroke care and enhancing patient outcomes. My responsibilities can be summarized as follows: \\n\\uf0b7 \\nConducted thorough data analysis to identify hours with a higher ratio of blasts in comparison to other periods. This \\nanalysis helped in pinpointing the critical timeframes that required immediate attention. \\n\\uf0b7 \\nDeveloped an AI system utilizing Machine Learning techniques to predict the probability of blasts occurring within \\nspecific time periods. This system provided valuable insights into the likelihood of stroke emergencies. \\n\\uf0b7 \\nUtilized the AI system\\'s output to effectively allocate resources, including doctors and medical staff, during the \\nidentified timeframes with higher blast probabilities. This strategic resource management approach optimized \\nresponse times and minimized costs. \\nMachine Learning Engineer | Fiver | San Francisco, CA | November 2020 - January 2022 \\n\\uf0b7 \\nSuccessfully completed diverse freelance projects encompassing Machine Learning, Deep Learning, and NLP, \\ninvolving tasks such as Classification, Regression, CNN, and Transfer Learning. \\n\\uf0b7 \\nLeveraged powerful tools and libraries like TensorFlow, Keras, and scikit-learn to develop and experiment with \\nvarious models, ensuring thorough research and effective development. \\n\\uf0b7 \\nProficiency in web application development using Django and Flask frameworks, enabling the creation of \\ncomprehensive solutions that seamlessly integrate machine learning capabilities into web-based platforms.\\nN/A \\n \\n \\nPROJECTS \\nFYP â€“ Mobile Application for Blind Person Navigate through Voice Message \\n\\uf0b7 \\nDeveloped a mobile application as a Final Year Project (FYP) to assist blind individuals in navigating through voice \\nmessages. \\n\\uf0b7 \\nLeveraged the TensorFlow Lite API as a crucial tool for integrating the model with the mobile interface, \\nenabling seamless communication. \\n\\uf0b7 \\nEmployed transfer learning techniques and trained the model on custom data, achieving an impressive accuracy rate \\nof 96%. \\nResearch on Heart failure clinical records Data Set \\n\\uf0b7 \\nConducted research on a Heart Failure clinical records dataset to investigate the importance of features using \\nvarious statistical tests, aiming to gain insights into predictive factors for heart failure. \\n\\uf0b7 \\nImplemented machine learning models to improve the accuracy of heart failure prediction, successfully achieving a \\nsignificant improvement of 4% (97%) accuracy compared to previous models. This enhanced accuracy can contribute \\nto more effective identification and management of heart failure cases. \\nAI Title Docs \\n\\uf0b7 \\nThe \"Document Classifier\" automates the classification of title closing documents using the BERT model, \\nimproving efficiency and accuracy in document processing. \\n\\uf0b7 \\nThe implementation of the AI-based system with a full pipeline through SageMaker, Lambda, and API Gateway offers \\na comprehensive solution that enhances productivity, reduces manual effort, and minimizes misclassification risks in \\nmortgage and lending processes. \\n\\uf0b7 \\nPowered by BERT, the Document Classifier sets new industry standards by enabling smoother workflows, \\nseamless integration, and advanced document management in the mortgage and lending sector. \\nGPT Training on Text Data for Advanced NLP Generation & Analysis \\n\\uf0b7 \\nConducted GPT training on text data using Hugging Face, a leading library for natural language processing (NLP) \\ntasks. \\n\\uf0b7 \\nLeveraged Hugging Face\\'s tools and models to train the GPT model on large-scale text datasets, enabling \\nadvanced natural language generation and analysis. \\n\\uf0b7 \\nExplored various techniques and approaches within Hugging Face to optimize the GPT model\\'s performance for \\ntasks such as text generation. \\n \\nCERTIFICATIONS \\nStructured Query Language (SQL) | HackerRank | 2022 \\nThe SQL certificate is relevant as it demonstrates proficiency in database management and querying skills, essential for roles in \\ndata analysis, database administration, and software development. \\nPandas | Kaggle | 2021 \\nThe Pandas certificate is relevant as it validates expertise in utilizing the powerful Pandas library for effective data \\nmanipulation and analysis, a crucial skill in data analysis and data science. \\nCertified Data Scientist | Professional Freelancing Training Program | 2021 \\nThe Certified Data Scientist certificate validates advanced skills in data science, including data preprocessing, machine \\nlearning, and statistical analysis, making it valuable for pursuing data-driven career opportunities. \\nArtificial Intelligence | Professional Freelancing Training Program | 2021 \\nThe Artificial Intelligence certificate validates specialized knowledge and skills in AI, including algorithm design and \\nimplementation, machine learning, and deep learning, enhancing career prospects in AI research, development, and \\napplication. \\nIntroduction to Programming Using Python | HackerRank | 2020 \\nThe certificate in \"Introduction to Programming Using Python\" validates foundational programming knowledge and \\nproficiency in Python, essential for entry-level programming roles and further studies in programming.\\nN/A \\n \\nN/A \\n \\nEDUCATION \\nBachelor of Software Engineering | Minor in Data Science, Web Development, HCI | National Textile \\nUniversity | Faisalabad, PK | 2021 | 3.52 \\nF.Sc. Pre-Engineering | Minor in Mathematics | Army Public School & College | Gujranwala \\nCantt | 2016 | 75% \\n \\n \\nSKILLS \\nMachine Learning: sci-kit-learn, TensorFlow, PyTorch \\nData Analysis: Pandas, NumPy, SciPy, matplotlib, seaborn, Plotly  \\nDeep Learning: TensorFlow, PyTorch \\nComputer Vision: OpenCV \\nNatural Language Processing (NLP): NLTK, spaCy, Gensim \\nWeb Development: Flask, Django \\nDesktop Application: Tkinter \\nMLops: AWS EC2, AWS Elastic Beanstalk, AWS Lambda, SageMaker, API Gateway\\n')]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parser = StrOutputParser()"
      ],
      "metadata": {
        "id": "cs4HTkjjkjuB"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_prompt = prompt.invoke({\"job_description\": job_description, \"resume\": retriever[1].page_content})"
      ],
      "metadata": {
        "id": "gwbHTPQBlIKx"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2lETHCAljbq",
        "outputId": "a2789ec5-7d3b-4bfd-8228-9e6449855e3f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StringPromptValue(text='\\nYou are a smart and precise Resume Analyzer.\\n\\nYou are given a **Job Description** and a candidate\\'s **Resume** (in plain text format).\\nYour task is to analyze how well the resume matches the job requirements and return a detailed, structured report.\\n\\nðŸ”¹ ONLY use the resume content for your answers.  \\nðŸ”¹ If any information is missing from the resume, write \"Not Found\".\\n\\n---\\n\\nðŸ“„ **Job Description**:\\n\\nðŸ§‘\\u200dðŸ’¼ Job Title: Data Scientist\\nWe are seeking a Data Scientist with a strong foundation in data analysis, machine learning, and statistical modeling. The ideal candidate will be responsible for extracting insights from complex datasets, building predictive models, and communicating findings that drive business decisions.\\n\\nKey Responsibilities\\nAnalyze large datasets to discover trends, patterns, and actionable insights.\\n\\nBuild and deploy machine learning models for classification, regression, and clustering tasks.\\n\\nCollaborate with engineering teams to integrate models into production systems.\\n\\nUse tools like Python, SQL, Pandas, and Scikit-learn for data processing and modeling.\\n\\nCommunicate results clearly to both technical and non-technical stakeholders.\\n\\nQualifications\\nProficiency in Python, SQL, and ML frameworks (e.g., Scikit-learn, TensorFlow).\\n\\nStrong background in statistics, data wrangling, and visualization.\\n\\nHands-on experience with data science projects, including model evaluation and tuning.\\n\\nExperience with data tools (Jupyter, Airflow, Tableau) and cloud platforms (AWS/GCP).\\n\\n\\nðŸ“ƒ **Resume**:\\nN/A \\n \\nN/A \\nMuhammad Talha \\nGujranwala, Punjab, Pakistan       \\n muhammadtalha1818@gmail.com       \\n+923444300394 \\n \\n https://www.linkedin.com/in/muhammad-talha-b643641b2/ \\n https://github.com/Talha1818 \\n \\n \\n  \\nSUMMARY \\nHighly experienced in the domains of machine learning, deep learning, and natural language processing (NLP), I am a \\npassionate engineer and thriving analyst. With a strong aptitude for applying ML techniques and developing advanced \\nalgorithms, I excel in solving complex real-world problems. My profound interest lies in research, Artificial Intelligence, and \\nrobotics, as I continuously strive to explore innovative frontiers and contribute to advancements in these fields. \\n \\nEXPERIENCE \\nFreelance | Upwork | San Francisco, CA | Feb 2024 - Present \\n\\uf0b7 \\nA freelance specialist adept at delivering impactful solutions in machine learning and AI realms, specializing in NLP, \\nLLMs, and generative AI technologies. From conceptualization to deployment, I craft tailored solutions utilizing \\nadvanced algorithms to tackle intricate problems and spark innovation in data analytics and AI applications. \\nMachine Learning Engineer | TransData | Lahore, PK | October 2022 â€“ March 2024 \\n\\uf0b7 \\nContributed to the development and implementation of the \"Document Classifier\" at TransData, an advanced AI \\nsystem for automating the classification of title closing documents in the mortgage and lending industry. \\n\\uf0b7 \\nLeveraged AI technology, specifically BERT, to create a cutting-edge solution that increased productivity, reduced \\nmanual effort, minimized misclassification risks, and improved document management workflows. The machine \\nlearning models deployed achieved a prediction accuracy score of over 98%, significantly reducing end-to-end \\nprocessing time. \\n\\uf0b7 \\nLeveraged AWS Cloud services to enhance scalability and reliability, implementing a Title Docs AI system. Created an \\nAPI using AWS Lambda and API Gateway to provide seamless integration and efficient communication between the \\napplication and the cloud infrastructure. \\nMachine Learning Engineer | BLING | San Francisco, CA | September 2022 - March 2023 \\n\\uf0b7 \\nAt BLING, I played a key role in projects related to message spam detection and sentiment analysis. Additionally, I \\ncontributed to the development of a GPT-powered chatbot to improve user experiences by effectively filtering out \\nspam, extracting sentiment insights, and providing accurate responses to user inquiries. \\n\\uf0b7 \\nMoreover, we successfully handled API implementation on AWS, utilizing services such as AWS Lambda and API \\nGateway. This allowed seamless integration and efficient communication between our applications and the cloud \\ninfrastructure, ensuring robust and scalable performance. \\nMachine Learning Engineer | HAWKLOGIX | Lahore, PK | February 2022 - August 2022 \\n\\uf0b7 \\nAt HAWKLOGIX, I worked on the TeleStroke evaluation project aimed at improving the hospital\\'s response time to \\nemergency stroke care and enhancing patient outcomes. My responsibilities can be summarized as follows: \\n\\uf0b7 \\nConducted thorough data analysis to identify hours with a higher ratio of blasts in comparison to other periods. This \\nanalysis helped in pinpointing the critical timeframes that required immediate attention. \\n\\uf0b7 \\nDeveloped an AI system utilizing Machine Learning techniques to predict the probability of blasts occurring within \\nspecific time periods. This system provided valuable insights into the likelihood of stroke emergencies. \\n\\uf0b7 \\nUtilized the AI system\\'s output to effectively allocate resources, including doctors and medical staff, during the \\nidentified timeframes with higher blast probabilities. This strategic resource management approach optimized \\nresponse times and minimized costs. \\nMachine Learning Engineer | Fiver | San Francisco, CA | November 2020 - January 2022 \\n\\uf0b7 \\nSuccessfully completed diverse freelance projects encompassing Machine Learning, Deep Learning, and NLP, \\ninvolving tasks such as Classification, Regression, CNN, and Transfer Learning. \\n\\uf0b7 \\nLeveraged powerful tools and libraries like TensorFlow, Keras, and scikit-learn to develop and experiment with \\nvarious models, ensuring thorough research and effective development. \\n\\uf0b7 \\nProficiency in web application development using Django and Flask frameworks, enabling the creation of \\ncomprehensive solutions that seamlessly integrate machine learning capabilities into web-based platforms.\\nN/A \\n \\n \\nPROJECTS \\nFYP â€“ Mobile Application for Blind Person Navigate through Voice Message \\n\\uf0b7 \\nDeveloped a mobile application as a Final Year Project (FYP) to assist blind individuals in navigating through voice \\nmessages. \\n\\uf0b7 \\nLeveraged the TensorFlow Lite API as a crucial tool for integrating the model with the mobile interface, \\nenabling seamless communication. \\n\\uf0b7 \\nEmployed transfer learning techniques and trained the model on custom data, achieving an impressive accuracy rate \\nof 96%. \\nResearch on Heart failure clinical records Data Set \\n\\uf0b7 \\nConducted research on a Heart Failure clinical records dataset to investigate the importance of features using \\nvarious statistical tests, aiming to gain insights into predictive factors for heart failure. \\n\\uf0b7 \\nImplemented machine learning models to improve the accuracy of heart failure prediction, successfully achieving a \\nsignificant improvement of 4% (97%) accuracy compared to previous models. This enhanced accuracy can contribute \\nto more effective identification and management of heart failure cases. \\nAI Title Docs \\n\\uf0b7 \\nThe \"Document Classifier\" automates the classification of title closing documents using the BERT model, \\nimproving efficiency and accuracy in document processing. \\n\\uf0b7 \\nThe implementation of the AI-based system with a full pipeline through SageMaker, Lambda, and API Gateway offers \\na comprehensive solution that enhances productivity, reduces manual effort, and minimizes misclassification risks in \\nmortgage and lending processes. \\n\\uf0b7 \\nPowered by BERT, the Document Classifier sets new industry standards by enabling smoother workflows, \\nseamless integration, and advanced document management in the mortgage and lending sector. \\nGPT Training on Text Data for Advanced NLP Generation & Analysis \\n\\uf0b7 \\nConducted GPT training on text data using Hugging Face, a leading library for natural language processing (NLP) \\ntasks. \\n\\uf0b7 \\nLeveraged Hugging Face\\'s tools and models to train the GPT model on large-scale text datasets, enabling \\nadvanced natural language generation and analysis. \\n\\uf0b7 \\nExplored various techniques and approaches within Hugging Face to optimize the GPT model\\'s performance for \\ntasks such as text generation. \\n \\nCERTIFICATIONS \\nStructured Query Language (SQL) | HackerRank | 2022 \\nThe SQL certificate is relevant as it demonstrates proficiency in database management and querying skills, essential for roles in \\ndata analysis, database administration, and software development. \\nPandas | Kaggle | 2021 \\nThe Pandas certificate is relevant as it validates expertise in utilizing the powerful Pandas library for effective data \\nmanipulation and analysis, a crucial skill in data analysis and data science. \\nCertified Data Scientist | Professional Freelancing Training Program | 2021 \\nThe Certified Data Scientist certificate validates advanced skills in data science, including data preprocessing, machine \\nlearning, and statistical analysis, making it valuable for pursuing data-driven career opportunities. \\nArtificial Intelligence | Professional Freelancing Training Program | 2021 \\nThe Artificial Intelligence certificate validates specialized knowledge and skills in AI, including algorithm design and \\nimplementation, machine learning, and deep learning, enhancing career prospects in AI research, development, and \\napplication. \\nIntroduction to Programming Using Python | HackerRank | 2020 \\nThe certificate in \"Introduction to Programming Using Python\" validates foundational programming knowledge and \\nproficiency in Python, essential for entry-level programming roles and further studies in programming.\\nN/A \\n \\nN/A \\n \\nEDUCATION \\nBachelor of Software Engineering | Minor in Data Science, Web Development, HCI | National Textile \\nUniversity | Faisalabad, PK | 2021 | 3.52 \\nF.Sc. Pre-Engineering | Minor in Mathematics | Army Public School & College | Gujranwala \\nCantt | 2016 | 75% \\n \\n \\nSKILLS \\nMachine Learning: sci-kit-learn, TensorFlow, PyTorch \\nData Analysis: Pandas, NumPy, SciPy, matplotlib, seaborn, Plotly  \\nDeep Learning: TensorFlow, PyTorch \\nComputer Vision: OpenCV \\nNatural Language Processing (NLP): NLTK, spaCy, Gensim \\nWeb Development: Flask, Django \\nDesktop Application: Tkinter \\nMLops: AWS EC2, AWS Elastic Beanstalk, AWS Lambda, SageMaker, API Gateway\\n\\n\\n---\\n\\nâœï¸ Now generate the following structured report:\\n\\n1. âœ… **Match Score (0â€“100%)** â€” Based on skills, experience, education relevance.\\n2. ðŸŽ“ **Education** â€” Summarize degree(s), institution(s), and relevant fields.\\n3. ðŸ’¼ **Experience** â€” Summarize past job roles, companies, and durations.\\n4. ðŸ› ï¸ **Skills / Strengths** â€” Extract technical and soft skills.\\n5. â¸ï¸ **Employment Gaps** â€” If any, mention time periods and durations.\\n6. ðŸ“ž **Contact Info** â€” Extract email, phone number, LinkedIn (if available).\\n7. ðŸ“ **Summary** â€” Short paragraph on how well this candidate fits the job.\\n\\nOnly output the report â€” do not provide explanations or repeat the resume/job description.\\n')"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "main_chain =  prompt | llm | parser"
      ],
      "metadata": {
        "id": "UDZSh3R3kxau"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = main_chain.invoke({\"job_description\": job_description, \"resume\": retriever[1].page_content})\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSz_NnlMk6GG",
        "outputId": "8824a4d6-fd38-47e4-8a87-b51e8697faab"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Match Score (0â€“100%):** 85%\n",
            "\n",
            "**Education:**\n",
            "\n",
            "* Bachelor of Software Engineering, Minor in Data Science, Web Development, HCI, National Textile University, Faisalabad, PK, 2021, 3.52\n",
            "* F.Sc. Pre-Engineering, Minor in Mathematics, Army Public School & College, Gujranwala Cantt, 2016, 75%\n",
            "\n",
            "**Experience:**\n",
            "\n",
            "* Freelance, Upwork, San Francisco, CA, Feb 2024 - Present\n",
            "* Machine Learning Engineer, TransData, Lahore, PK, October 2022 â€“ March 2024\n",
            "* Machine Learning Engineer, BLING, San Francisco, CA, September 2022 - March 2023\n",
            "* Machine Learning Engineer, HAWKLOGIX, Lahore, PK, February 2022 - August 2022\n",
            "* Machine Learning Engineer, Fiver, San Francisco, CA, November 2020 - January 2022\n",
            "\n",
            "**Skills / Strengths:**\n",
            "\n",
            "* Machine Learning: sci-kit-learn, TensorFlow, PyTorch\n",
            "* Data Analysis: Pandas, NumPy, SciPy, matplotlib, seaborn, Plotly\n",
            "* Deep Learning: TensorFlow, PyTorch\n",
            "* Computer Vision: OpenCV\n",
            "* Natural Language Processing (NLP): NLTK, spaCy, Gensim\n",
            "* Web Development: Flask, Django\n",
            "* Desktop Application: Tkinter\n",
            "* MLOps: AWS EC2, AWS Elastic Beanstalk, AWS Lambda, SageMaker, API Gateway\n",
            "\n",
            "**Employment Gaps:** None mentioned\n",
            "\n",
            "**Contact Info:**\n",
            "\n",
            "* Email: muhammadtalha1818@gmail.com\n",
            "* Phone Number: +923444300394\n",
            "* LinkedIn: https://www.linkedin.com/in/muhammad-talha-b643641b2/\n",
            "\n",
            "**Summary:** The candidate has a strong background in machine learning, deep learning, and NLP, with experience in developing and implementing AI systems. They have a solid foundation in data analysis and visualization, and are proficient in various programming languages and tools. The candidate's skills and experience align well with the job requirements, making them a strong fit for the Data Scientist position.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# answer = llm.invoke(final_prompt)\n",
        "# print(answer.content)"
      ],
      "metadata": {
        "id": "Rsz8DSDxk77k"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from typing import List, Optional\n",
        "\n",
        "\n",
        "class Education(BaseModel):\n",
        "    university_name: str = Field(..., description=\"Name of the university or institution\")\n",
        "    degree: str = Field(..., description=\"Degree earned by the candidate\")\n",
        "    gpa: Optional[str] = Field(None, description=\"GPA or grade, if available\")\n",
        "\n",
        "\n",
        "class Experience(BaseModel):\n",
        "    company_name: str = Field(..., description=\"Name of the company or organization\")\n",
        "    n_years: Optional[str] = Field(None, description=\"Duration in years at this company\")\n",
        "    project_name: Optional[str] = Field(None, description=\"Name or title of a key project\")\n",
        "    project_description: Optional[str] = Field(None, description=\"Brief description of the project\")\n",
        "    tech_stack: List[str] = Field(..., description=\"Technologies and tools used in the project\")\n",
        "\n",
        "\n",
        "class ContactInfo(BaseModel):\n",
        "    email: Optional[str] = Field(None, description=\"Email address\")\n",
        "    phone: Optional[str] = Field(None, description=\"Phone number\")\n",
        "    linkedin: Optional[str] = Field(None, description=\"LinkedIn profile URL\")\n",
        "\n",
        "\n",
        "class ResumeReport(BaseModel):\n",
        "    name: str = Field(..., description=\"Full name of the candidate\")\n",
        "    # age: Optional[int] = Field(None, ge=0, description=\"Age of the candidate, if available\")\n",
        "    # native_languages: List[str] = Field(default_factory=list, description=\"List of native languages spoken by the candidate\")\n",
        "    # match_score: int = Field(..., ge=0, le=100, description=\"Match score between 0â€“100\")\n",
        "    # match_score: str = Field(..., description=\"Match score between 0â€“100\")\n",
        "    education: Optional[List[Education]] = Field(..., description=\"List of education details\")\n",
        "    experience: Optional[List[Experience]] = Field(..., description=\"List of professional experience\")\n",
        "    skills: Optional[List[str]] = Field(..., description=\"List of key skills and strengths\")\n",
        "    employment_gaps: Optional[str] = Field(None, description=\"Employment gaps if found\")\n",
        "    contact_info: ContactInfo = Field(..., description=\"Contact information\")\n",
        "    summary: str = Field(..., description=\"Short summary about the candidate's fit for the job\")\n"
      ],
      "metadata": {
        "id": "NALnu3VTwOph"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import PydanticOutputParser\n",
        "\n",
        "resume_parser = PydanticOutputParser(pydantic_object=ResumeReport)"
      ],
      "metadata": {
        "id": "nVtGFYiTykAh"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "resume_prompt = PromptTemplate(\n",
        "    template=\"\"\"\n",
        "You are a smart and precise Resume Analyzer.\n",
        "\n",
        "You are given a **Job Description** and a candidate's **Resume** (plain text).\n",
        "Your task is to analyze how well the resume matches the job requirements and return a structured report as a VALID JSON object.\n",
        "\n",
        "ONLY use the resume content for your answers.\n",
        "If any information is missing from the resume, write \"Not Found\".\n",
        "\n",
        "---\n",
        "\n",
        "Job Description:\n",
        "{job_description}\n",
        "\n",
        "Resume:\n",
        "{resume}\n",
        "\n",
        "---\n",
        "\n",
        "Return ONLY a JSON object in the format below:\n",
        "{format_instructions}\n",
        "\"\"\",\n",
        "    input_variables=[\"job_description\", \"resume\"],\n",
        "    partial_variables={\"format_instructions\": resume_parser.get_format_instructions()}\n",
        ")\n"
      ],
      "metadata": {
        "id": "St4njtPLyl3a"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain.prompts import PromptTemplate\n",
        "\n",
        "# resume_prompt = PromptTemplate(\n",
        "#     template=\"\"\"\n",
        "# You are a smart and precise Resume Analyzer.\n",
        "\n",
        "# You are given a **Job Description** and a candidate's **Resume** (plain text).\n",
        "# Your task is to analyze how well the resume matches the job requirements and return a structured report as a VALID JSON object.\n",
        "\n",
        "# ðŸ”¹ ONLY use the resume content for your answers.\n",
        "# ðŸ”¹ If any information is missing from the resume, write \"Not Found\".\n",
        "\n",
        "# You are also given two similarity metrics:\n",
        "# - **Distance**: A float where lower means better match (e.g., 0.7 is good, 1.8 is weak).\n",
        "# - **Similarity Score**: A float between 0 and 1, calculated as `1 / (1 + distance)`.\n",
        "\n",
        "# ðŸŽ¯ Use the following formula to compute the `match_score` (between 0â€“100):\n",
        "# - match_score = round(((1 - min(distance, 2)) * 0.6 + similarity_score * 0.4) * 100, 2)\n",
        "\n",
        "# Explanation:\n",
        "# - Distance is capped at 2.0 to prevent outliers.\n",
        "# - 60% weight is from distance, 40% from normalized similarity_score.\n",
        "# - The result is always between 0 and 100.\n",
        "\n",
        "# ---\n",
        "\n",
        "# ðŸ“ Similarity Metrics:\n",
        "# - Distance: {distance}\n",
        "# - Similarity Score: {similarity_score}\n",
        "\n",
        "# ðŸ“„ Job Description:\n",
        "# {job_description}\n",
        "\n",
        "# ðŸ“ƒ Resume:\n",
        "# {resume}\n",
        "\n",
        "# ---\n",
        "\n",
        "# Return ONLY a JSON object in the format below:\n",
        "# {format_instructions}\n",
        "# \"\"\",\n",
        "#     input_variables=[\"job_description\", \"resume\", \"distance\", \"similarity_score\"],\n",
        "#     partial_variables={\"format_instructions\": resume_parser.get_format_instructions()}\n",
        "# )\n"
      ],
      "metadata": {
        "id": "sV--CS5uBpSS"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_chain =  resume_prompt | llm | resume_parser"
      ],
      "metadata": {
        "id": "RXtg66H3y0Tz"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever[1].metadata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ai4NHcKj_yBY",
        "outputId": "222ae453-f1ae-44b7-f555-7dc305e9f9de"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'source': '/content/drive/MyDrive/CV/Muhammad Talha - ML Engineer.pdf',\n",
              " 'score': np.float32(1.5776329),\n",
              " 'score_percent': np.float32(54.64),\n",
              " 'distance': np.float32(0.83004117)}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ret = retriever[1].page_content + f\"\\n\\n distance: {str(retriever[1].metadata['distance'])}\\n get score this formula similarity = 1 / (1 + distance)  # Normalized between 0 and 1 Score:{str(retriever[1].metadata['score'])}\"\n",
        "ret"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "O6ld2sUx_kUH",
        "outputId": "e909a32b-fcc9-4a33-a90b-2537468079b1"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'N/A \\n \\nN/A \\nMuhammad Talha \\nGujranwala, Punjab, Pakistan       \\n muhammadtalha1818@gmail.com       \\n+923444300394 \\n \\n https://www.linkedin.com/in/muhammad-talha-b643641b2/ \\n https://github.com/Talha1818 \\n \\n \\n  \\nSUMMARY \\nHighly experienced in the domains of machine learning, deep learning, and natural language processing (NLP), I am a \\npassionate engineer and thriving analyst. With a strong aptitude for applying ML techniques and developing advanced \\nalgorithms, I excel in solving complex real-world problems. My profound interest lies in research, Artificial Intelligence, and \\nrobotics, as I continuously strive to explore innovative frontiers and contribute to advancements in these fields. \\n \\nEXPERIENCE \\nFreelance | Upwork | San Francisco, CA | Feb 2024 - Present \\n\\uf0b7 \\nA freelance specialist adept at delivering impactful solutions in machine learning and AI realms, specializing in NLP, \\nLLMs, and generative AI technologies. From conceptualization to deployment, I craft tailored solutions utilizing \\nadvanced algorithms to tackle intricate problems and spark innovation in data analytics and AI applications. \\nMachine Learning Engineer | TransData | Lahore, PK | October 2022 â€“ March 2024 \\n\\uf0b7 \\nContributed to the development and implementation of the \"Document Classifier\" at TransData, an advanced AI \\nsystem for automating the classification of title closing documents in the mortgage and lending industry. \\n\\uf0b7 \\nLeveraged AI technology, specifically BERT, to create a cutting-edge solution that increased productivity, reduced \\nmanual effort, minimized misclassification risks, and improved document management workflows. The machine \\nlearning models deployed achieved a prediction accuracy score of over 98%, significantly reducing end-to-end \\nprocessing time. \\n\\uf0b7 \\nLeveraged AWS Cloud services to enhance scalability and reliability, implementing a Title Docs AI system. Created an \\nAPI using AWS Lambda and API Gateway to provide seamless integration and efficient communication between the \\napplication and the cloud infrastructure. \\nMachine Learning Engineer | BLING | San Francisco, CA | September 2022 - March 2023 \\n\\uf0b7 \\nAt BLING, I played a key role in projects related to message spam detection and sentiment analysis. Additionally, I \\ncontributed to the development of a GPT-powered chatbot to improve user experiences by effectively filtering out \\nspam, extracting sentiment insights, and providing accurate responses to user inquiries. \\n\\uf0b7 \\nMoreover, we successfully handled API implementation on AWS, utilizing services such as AWS Lambda and API \\nGateway. This allowed seamless integration and efficient communication between our applications and the cloud \\ninfrastructure, ensuring robust and scalable performance. \\nMachine Learning Engineer | HAWKLOGIX | Lahore, PK | February 2022 - August 2022 \\n\\uf0b7 \\nAt HAWKLOGIX, I worked on the TeleStroke evaluation project aimed at improving the hospital\\'s response time to \\nemergency stroke care and enhancing patient outcomes. My responsibilities can be summarized as follows: \\n\\uf0b7 \\nConducted thorough data analysis to identify hours with a higher ratio of blasts in comparison to other periods. This \\nanalysis helped in pinpointing the critical timeframes that required immediate attention. \\n\\uf0b7 \\nDeveloped an AI system utilizing Machine Learning techniques to predict the probability of blasts occurring within \\nspecific time periods. This system provided valuable insights into the likelihood of stroke emergencies. \\n\\uf0b7 \\nUtilized the AI system\\'s output to effectively allocate resources, including doctors and medical staff, during the \\nidentified timeframes with higher blast probabilities. This strategic resource management approach optimized \\nresponse times and minimized costs. \\nMachine Learning Engineer | Fiver | San Francisco, CA | November 2020 - January 2022 \\n\\uf0b7 \\nSuccessfully completed diverse freelance projects encompassing Machine Learning, Deep Learning, and NLP, \\ninvolving tasks such as Classification, Regression, CNN, and Transfer Learning. \\n\\uf0b7 \\nLeveraged powerful tools and libraries like TensorFlow, Keras, and scikit-learn to develop and experiment with \\nvarious models, ensuring thorough research and effective development. \\n\\uf0b7 \\nProficiency in web application development using Django and Flask frameworks, enabling the creation of \\ncomprehensive solutions that seamlessly integrate machine learning capabilities into web-based platforms.\\nN/A \\n \\n \\nPROJECTS \\nFYP â€“ Mobile Application for Blind Person Navigate through Voice Message \\n\\uf0b7 \\nDeveloped a mobile application as a Final Year Project (FYP) to assist blind individuals in navigating through voice \\nmessages. \\n\\uf0b7 \\nLeveraged the TensorFlow Lite API as a crucial tool for integrating the model with the mobile interface, \\nenabling seamless communication. \\n\\uf0b7 \\nEmployed transfer learning techniques and trained the model on custom data, achieving an impressive accuracy rate \\nof 96%. \\nResearch on Heart failure clinical records Data Set \\n\\uf0b7 \\nConducted research on a Heart Failure clinical records dataset to investigate the importance of features using \\nvarious statistical tests, aiming to gain insights into predictive factors for heart failure. \\n\\uf0b7 \\nImplemented machine learning models to improve the accuracy of heart failure prediction, successfully achieving a \\nsignificant improvement of 4% (97%) accuracy compared to previous models. This enhanced accuracy can contribute \\nto more effective identification and management of heart failure cases. \\nAI Title Docs \\n\\uf0b7 \\nThe \"Document Classifier\" automates the classification of title closing documents using the BERT model, \\nimproving efficiency and accuracy in document processing. \\n\\uf0b7 \\nThe implementation of the AI-based system with a full pipeline through SageMaker, Lambda, and API Gateway offers \\na comprehensive solution that enhances productivity, reduces manual effort, and minimizes misclassification risks in \\nmortgage and lending processes. \\n\\uf0b7 \\nPowered by BERT, the Document Classifier sets new industry standards by enabling smoother workflows, \\nseamless integration, and advanced document management in the mortgage and lending sector. \\nGPT Training on Text Data for Advanced NLP Generation & Analysis \\n\\uf0b7 \\nConducted GPT training on text data using Hugging Face, a leading library for natural language processing (NLP) \\ntasks. \\n\\uf0b7 \\nLeveraged Hugging Face\\'s tools and models to train the GPT model on large-scale text datasets, enabling \\nadvanced natural language generation and analysis. \\n\\uf0b7 \\nExplored various techniques and approaches within Hugging Face to optimize the GPT model\\'s performance for \\ntasks such as text generation. \\n \\nCERTIFICATIONS \\nStructured Query Language (SQL) | HackerRank | 2022 \\nThe SQL certificate is relevant as it demonstrates proficiency in database management and querying skills, essential for roles in \\ndata analysis, database administration, and software development. \\nPandas | Kaggle | 2021 \\nThe Pandas certificate is relevant as it validates expertise in utilizing the powerful Pandas library for effective data \\nmanipulation and analysis, a crucial skill in data analysis and data science. \\nCertified Data Scientist | Professional Freelancing Training Program | 2021 \\nThe Certified Data Scientist certificate validates advanced skills in data science, including data preprocessing, machine \\nlearning, and statistical analysis, making it valuable for pursuing data-driven career opportunities. \\nArtificial Intelligence | Professional Freelancing Training Program | 2021 \\nThe Artificial Intelligence certificate validates specialized knowledge and skills in AI, including algorithm design and \\nimplementation, machine learning, and deep learning, enhancing career prospects in AI research, development, and \\napplication. \\nIntroduction to Programming Using Python | HackerRank | 2020 \\nThe certificate in \"Introduction to Programming Using Python\" validates foundational programming knowledge and \\nproficiency in Python, essential for entry-level programming roles and further studies in programming.\\nN/A \\n \\nN/A \\n \\nEDUCATION \\nBachelor of Software Engineering | Minor in Data Science, Web Development, HCI | National Textile \\nUniversity | Faisalabad, PK | 2021 | 3.52 \\nF.Sc. Pre-Engineering | Minor in Mathematics | Army Public School & College | Gujranwala \\nCantt | 2016 | 75% \\n \\n \\nSKILLS \\nMachine Learning: sci-kit-learn, TensorFlow, PyTorch \\nData Analysis: Pandas, NumPy, SciPy, matplotlib, seaborn, Plotly  \\nDeep Learning: TensorFlow, PyTorch \\nComputer Vision: OpenCV \\nNatural Language Processing (NLP): NLTK, spaCy, Gensim \\nWeb Development: Flask, Django \\nDesktop Application: Tkinter \\nMLops: AWS EC2, AWS Elastic Beanstalk, AWS Lambda, SageMaker, API Gateway\\n\\n\\n distance: 0.83004117\\n get score this formula similarity = 1 / (1 + distance)  # Normalized between 0 and 1 Score:1.5776329'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# res = main_chain.invoke({\"job_description\": job_description, \"resume\": retriever[0].page_content})"
      ],
      "metadata": {
        "id": "KspkghCsyrH6"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# res = main_chain.invoke({\"job_description\": job_description, \"resume\": retriever[1].page_content,\n",
        "#                          \"distance\":retriever[1].metadata['distance'],\n",
        "#                          \"similarity_score\":retriever[1].metadata['score_percent']/100})"
      ],
      "metadata": {
        "id": "wQ_QPi2GD-tG"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = main_chain.invoke({\"job_description\": job_description, \"resume\": retriever[1].page_content})"
      ],
      "metadata": {
        "id": "APvgkWSJIG-f"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever[1].metadata['distance']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10pLOBdBEY00",
        "outputId": "f102b95b-1dfd-4bb6-ea33-a8137cde64ff"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float32(0.83004117)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_response = res.dict()\n",
        "final_response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5capyqVn0nxo",
        "outputId": "34bdd59f-7e6e-4df4-d181-1384c9068dee"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-43-3475066677.py:1: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
            "  final_response = res.dict()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'Muhammad Talha',\n",
              " 'education': [{'university_name': 'National Textile University',\n",
              "   'degree': 'Bachelor of Software Engineering',\n",
              "   'gpa': '3.52'}],\n",
              " 'experience': [{'company_name': 'TransData',\n",
              "   'n_years': '1.5',\n",
              "   'project_name': 'Document Classifier',\n",
              "   'project_description': 'Automated classification of title closing documents using BERT model',\n",
              "   'tech_stack': ['Python',\n",
              "    'SQL',\n",
              "    'AWS Cloud services',\n",
              "    'TensorFlow',\n",
              "    'BERT']},\n",
              "  {'company_name': 'BLING',\n",
              "   'n_years': '0.5',\n",
              "   'project_name': 'Message Spam Detection and Sentiment Analysis',\n",
              "   'project_description': 'Developed a GPT-powered chatbot for user experience improvement',\n",
              "   'tech_stack': ['Python', 'SQL', 'AWS Cloud services', 'TensorFlow', 'GPT']},\n",
              "  {'company_name': 'HAWKLOGIX',\n",
              "   'n_years': '0.5',\n",
              "   'project_name': 'TeleStroke Evaluation Project',\n",
              "   'project_description': 'Developed an AI system to predict probability of blasts occurring within specific time periods',\n",
              "   'tech_stack': ['Python',\n",
              "    'SQL',\n",
              "    'AWS Cloud services',\n",
              "    'Machine Learning techniques']},\n",
              "  {'company_name': 'Fiver',\n",
              "   'n_years': '1.5',\n",
              "   'project_name': 'Machine Learning, Deep Learning, and NLP projects',\n",
              "   'project_description': 'Completed diverse freelance projects involving tasks such as Classification, Regression, CNN, and Transfer Learning',\n",
              "   'tech_stack': ['Python', 'SQL', 'TensorFlow', 'Keras', 'scikit-learn']}],\n",
              " 'skills': ['Machine Learning',\n",
              "  'Data Analysis',\n",
              "  'Deep Learning',\n",
              "  'Computer Vision',\n",
              "  'Natural Language Processing',\n",
              "  'Web Development',\n",
              "  'Desktop Application',\n",
              "  'MLops'],\n",
              " 'employment_gaps': None,\n",
              " 'contact_info': {'email': 'muhammadtalha1818@gmail.com',\n",
              "  'phone': '+923444300394',\n",
              "  'linkedin': 'https://www.linkedin.com/in/muhammad-talha-b643641b2/'},\n",
              " 'summary': 'Highly experienced in machine learning, deep learning, and natural language processing (NLP), I am a passionate engineer and thriving analyst.'}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_metadata(doc):\n",
        "  distance = round(float(doc.metadata['distance']),4)\n",
        "  score = round(float(doc.metadata['score_percent']),4)\n",
        "  source = doc.metadata['source']\n",
        "  return {\n",
        "      'distance': distance,\n",
        "      'score': score,\n",
        "      'source': source\n",
        "  }"
      ],
      "metadata": {
        "id": "ih3U7r5Z8UuN"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_metadata(retriever[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EG9-XVy19PHx",
        "outputId": "e539d15c-2fa4-4a40-ec74-86e0fbd3e830"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'distance': 0.83,\n",
              " 'score': 54.64,\n",
              " 'source': '/content/drive/MyDrive/CV/Muhammad Talha - ML Engineer.pdf'}"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# retriever[1].metadata"
      ],
      "metadata": {
        "id": "YFaw011m8pKV"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_response['metadata'] = get_metadata(retriever[1])\n",
        "final_response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdTLCOQF8OZM",
        "outputId": "141f8c11-cd76-4c64-be84-4274d97315a2"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'Muhammad Talha',\n",
              " 'education': [{'university_name': 'National Textile University',\n",
              "   'degree': 'Bachelor of Software Engineering',\n",
              "   'gpa': '3.52'}],\n",
              " 'experience': [{'company_name': 'TransData',\n",
              "   'n_years': '1.5',\n",
              "   'project_name': 'Document Classifier',\n",
              "   'project_description': 'Automated classification of title closing documents using BERT model',\n",
              "   'tech_stack': ['Python',\n",
              "    'SQL',\n",
              "    'AWS Cloud services',\n",
              "    'TensorFlow',\n",
              "    'BERT']},\n",
              "  {'company_name': 'BLING',\n",
              "   'n_years': '0.5',\n",
              "   'project_name': 'Message Spam Detection and Sentiment Analysis',\n",
              "   'project_description': 'Developed a GPT-powered chatbot for user experience improvement',\n",
              "   'tech_stack': ['Python', 'SQL', 'AWS Cloud services', 'TensorFlow', 'GPT']},\n",
              "  {'company_name': 'HAWKLOGIX',\n",
              "   'n_years': '0.5',\n",
              "   'project_name': 'TeleStroke Evaluation Project',\n",
              "   'project_description': 'Developed an AI system to predict probability of blasts occurring within specific time periods',\n",
              "   'tech_stack': ['Python',\n",
              "    'SQL',\n",
              "    'AWS Cloud services',\n",
              "    'Machine Learning techniques']},\n",
              "  {'company_name': 'Fiver',\n",
              "   'n_years': '1.5',\n",
              "   'project_name': 'Machine Learning, Deep Learning, and NLP projects',\n",
              "   'project_description': 'Completed diverse freelance projects involving tasks such as Classification, Regression, CNN, and Transfer Learning',\n",
              "   'tech_stack': ['Python', 'SQL', 'TensorFlow', 'Keras', 'scikit-learn']}],\n",
              " 'skills': ['Machine Learning',\n",
              "  'Data Analysis',\n",
              "  'Deep Learning',\n",
              "  'Computer Vision',\n",
              "  'Natural Language Processing',\n",
              "  'Web Development',\n",
              "  'Desktop Application',\n",
              "  'MLops'],\n",
              " 'employment_gaps': None,\n",
              " 'contact_info': {'email': 'muhammadtalha1818@gmail.com',\n",
              "  'phone': '+923444300394',\n",
              "  'linkedin': 'https://www.linkedin.com/in/muhammad-talha-b643641b2/'},\n",
              " 'summary': 'Highly experienced in machine learning, deep learning, and natural language processing (NLP), I am a passionate engineer and thriving analyst.',\n",
              " 'metadata': {'distance': 0.83,\n",
              "  'score': 54.64,\n",
              "  'source': '/content/drive/MyDrive/CV/Muhammad Talha - ML Engineer.pdf'}}"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def extract_float_from_text(text: str) -> float:\n",
        "    \"\"\"\n",
        "    Extracts the first numeric value (integer or float) from a string.\n",
        "\n",
        "    Args:\n",
        "        text (str): Input string, e.g., '1 years' or '0.5 years'.\n",
        "\n",
        "    Returns:\n",
        "        float: Extracted number as float, or 0.0 if no number is found.\n",
        "    \"\"\"\n",
        "    match = re.search(r\"\\d+(\\.\\d+)?\", text)\n",
        "    return float(match.group()) if match else 0.0\n",
        "\n",
        "print(extract_float_from_text(\"1 years\"))     # Output: 1.0\n",
        "print(extract_float_from_text(\"0.5 years\"))   # Output: 0.5\n",
        "print(extract_float_from_text(\"10 years\"))   # Output: 0.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEAB8xG5v8JL",
        "outputId": "6f1c14d3-acbc-485b-8a02-eca0100a8548"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "0.5\n",
            "10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def extract_years_from_text(text: str) -> float:\n",
        "    \"\"\"\n",
        "    Extracts a numeric value (float/int) from a string and converts months to years if needed.\n",
        "\n",
        "    Args:\n",
        "        text (str): e.g., '6-12 months', '0.5 years', '1 year'\n",
        "\n",
        "    Returns:\n",
        "        float: Duration in years\n",
        "    \"\"\"\n",
        "    match = re.search(r\"\\d+(\\.\\d+)?\", text)\n",
        "    if not match:\n",
        "        return 0.0\n",
        "\n",
        "    value = float(match.group())\n",
        "\n",
        "    if 'month' in text.lower():\n",
        "        return round(value / 12, 2)\n",
        "    else:\n",
        "        return round(value, 2)\n"
      ],
      "metadata": {
        "id": "fjjEjGe21f2O"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(extract_years_from_text(\"6-12 months\"))   # Output: 0.5\n",
        "print(extract_years_from_text(\"1 year\"))        # Output: 1.0\n",
        "print(extract_years_from_text(\"0.5 years\"))     # Output: 0.5\n",
        "print(extract_years_from_text(\"18 months\"))     # Output: 1.5\n",
        "print(extract_years_from_text(\"No duration\"))   # Output: 0.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4Qz1lFo1iCP",
        "outputId": "e91dfa2b-eb01-4566-ec36-7a7c813efc6a"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5\n",
            "1.0\n",
            "0.5\n",
            "1.5\n",
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total = 0\n",
        "for exp in final_response['experience']:\n",
        "  yrs = extract_float_from_text(exp['n_years'])\n",
        "  total += yrs\n",
        "print(total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8ej7nyAvtb8",
        "outputId": "796007f9-27cd-4d1a-b0e5-e7f831ad8d38"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame([final_response])\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "m5yAR2_k3s3r",
        "outputId": "767c09da-bebc-4548-f96d-f41e9389208f"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             name                                          education  \\\n",
              "0  Muhammad Talha  [{'university_name': 'National Textile Univers...   \n",
              "\n",
              "                                          experience  \\\n",
              "0  [{'company_name': 'TransData', 'n_years': '1.5...   \n",
              "\n",
              "                                              skills employment_gaps  \\\n",
              "0  [Machine Learning, Data Analysis, Deep Learnin...            None   \n",
              "\n",
              "                                        contact_info  \\\n",
              "0  {'email': 'muhammadtalha1818@gmail.com', 'phon...   \n",
              "\n",
              "                                             summary  \\\n",
              "0  Highly experienced in machine learning, deep l...   \n",
              "\n",
              "                                            metadata  \n",
              "0  {'distance': 0.83, 'score': 54.64, 'source': '...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f6030b4e-c281-4904-a9c5-2954ff955bd2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>education</th>\n",
              "      <th>experience</th>\n",
              "      <th>skills</th>\n",
              "      <th>employment_gaps</th>\n",
              "      <th>contact_info</th>\n",
              "      <th>summary</th>\n",
              "      <th>metadata</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Muhammad Talha</td>\n",
              "      <td>[{'university_name': 'National Textile Univers...</td>\n",
              "      <td>[{'company_name': 'TransData', 'n_years': '1.5...</td>\n",
              "      <td>[Machine Learning, Data Analysis, Deep Learnin...</td>\n",
              "      <td>None</td>\n",
              "      <td>{'email': 'muhammadtalha1818@gmail.com', 'phon...</td>\n",
              "      <td>Highly experienced in machine learning, deep l...</td>\n",
              "      <td>{'distance': 0.83, 'score': 54.64, 'source': '...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f6030b4e-c281-4904-a9c5-2954ff955bd2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f6030b4e-c281-4904-a9c5-2954ff955bd2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f6030b4e-c281-4904-a9c5-2954ff955bd2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_b8a51999-20ff-472a-911c-dbe60b1cb4ce\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_b8a51999-20ff-472a-911c-dbe60b1cb4ce button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RESULTS = []\n",
        "def get_all_cv_results(retriever_docs):\n",
        "\n",
        "  for retriever in retriever_docs:\n",
        "    res = main_chain.invoke({\"job_description\": job_description, \"resume\": retriever.page_content}).model_dump()\n",
        "    metadata = get_metadata(retriever)\n",
        "    res['metadata'] = metadata\n",
        "    res['label'] = label_score_by_distance(metadata['distance'])\n",
        "    res['match_score'] = metadata['score']\n",
        "    total = 0\n",
        "    for exp in res['experience']:\n",
        "      yrs = extract_years_from_text(exp['n_years'])\n",
        "      total += yrs\n",
        "    res['total_experience'] = total\n",
        "    RESULTS.append(res)\n",
        "  return RESULTS"
      ],
      "metadata": {
        "id": "kqmBhqSe5_ZV"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RESPONSE = get_all_cv_results(retriever)"
      ],
      "metadata": {
        "id": "l7iEex6z7xBP"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RESPONSE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3S4Tuz871L8",
        "outputId": "35ddf328-a32d-441d-b9a7-29539df2b36a"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'name': 'Muhammad Talha',\n",
              "  'education': [{'university_name': 'National Textile University Faisalabaad',\n",
              "    'degree': 'Bachelor of Computer Science',\n",
              "    'gpa': 'Not Found'}],\n",
              "  'experience': [{'company_name': 'Not Found',\n",
              "    'n_years': '1 year',\n",
              "    'project_name': 'JARVIS Voice Assistant AI',\n",
              "    'project_description': 'Python project',\n",
              "    'tech_stack': ['Python', 'Machine Learning']}],\n",
              "  'skills': ['Programming',\n",
              "   'Logical and Structured Thinking',\n",
              "   'Coding in Multiple Languages (Python, Java, C++ etc)',\n",
              "   'Ability to work by myself',\n",
              "   'Ability to work harmoniously with other members',\n",
              "   'Analytical and problem solving skills'],\n",
              "  'employment_gaps': 'Not Found',\n",
              "  'contact_info': {'email': 'muhammadtalha1818@gmail.com',\n",
              "   'phone': '+923444300394',\n",
              "   'linkedin': 'Not Found'},\n",
              "  'summary': 'Not Found',\n",
              "  'metadata': {'distance': 0.7845,\n",
              "   'score': 56.04,\n",
              "   'source': '/content/drive/MyDrive/CV/MuhammadTalhaCV1.pdf'},\n",
              "  'label': 'Strong match',\n",
              "  'match_score': 56.04,\n",
              "  'total_experience': 1.0},\n",
              " {'name': 'Muhammad Talha',\n",
              "  'education': [{'university_name': 'National Textile University',\n",
              "    'degree': 'Bachelor of Software Engineering',\n",
              "    'gpa': '3.52'}],\n",
              "  'experience': [{'company_name': 'TransData',\n",
              "    'n_years': '1.5',\n",
              "    'project_name': 'Document Classifier',\n",
              "    'project_description': 'Automated classification of title closing documents using BERT model',\n",
              "    'tech_stack': ['Python',\n",
              "     'SQL',\n",
              "     'AWS Cloud services',\n",
              "     'TensorFlow',\n",
              "     'BERT']},\n",
              "   {'company_name': 'BLING',\n",
              "    'n_years': '0.5',\n",
              "    'project_name': 'Message Spam Detection and Sentiment Analysis',\n",
              "    'project_description': 'Developed a GPT-powered chatbot for user experience improvement',\n",
              "    'tech_stack': ['Python',\n",
              "     'SQL',\n",
              "     'AWS Cloud services',\n",
              "     'TensorFlow',\n",
              "     'GPT']},\n",
              "   {'company_name': 'HAWKLOGIX',\n",
              "    'n_years': '0.5',\n",
              "    'project_name': 'TeleStroke Evaluation Project',\n",
              "    'project_description': 'Developed an AI system to predict probability of blasts occurring within specific time periods',\n",
              "    'tech_stack': ['Python',\n",
              "     'SQL',\n",
              "     'AWS Cloud services',\n",
              "     'Machine Learning techniques']},\n",
              "   {'company_name': 'Fiver',\n",
              "    'n_years': '1.5',\n",
              "    'project_name': 'Machine Learning, Deep Learning, and NLP projects',\n",
              "    'project_description': 'Completed diverse freelance projects involving tasks such as Classification, Regression, CNN, and Transfer Learning',\n",
              "    'tech_stack': ['Python', 'SQL', 'TensorFlow', 'Keras', 'scikit-learn']}],\n",
              "  'skills': ['Machine Learning',\n",
              "   'Data Analysis',\n",
              "   'Deep Learning',\n",
              "   'Computer Vision',\n",
              "   'Natural Language Processing',\n",
              "   'Web Development',\n",
              "   'Desktop Application',\n",
              "   'MLops'],\n",
              "  'employment_gaps': None,\n",
              "  'contact_info': {'email': 'muhammadtalha1818@gmail.com',\n",
              "   'phone': '+923444300394',\n",
              "   'linkedin': 'https://www.linkedin.com/in/muhammad-talha-b643641b2/'},\n",
              "  'summary': 'Highly experienced in machine learning, deep learning, and natural language processing (NLP), I am a passionate engineer and thriving analyst.',\n",
              "  'metadata': {'distance': 0.83,\n",
              "   'score': 54.64,\n",
              "   'source': '/content/drive/MyDrive/CV/Muhammad Talha - ML Engineer.pdf'},\n",
              "  'label': 'Moderate match',\n",
              "  'match_score': 54.64,\n",
              "  'total_experience': 4.0}]"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(RESPONSE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvP2zOS9722t",
        "outputId": "57d152c6-0971-4e9f-c349-7e0b05554d6e"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(RESPONSE)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "XE_SjsWu79kV",
        "outputId": "3b1a1220-7166-4bad-edad-4e6f3d795954"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             name                                          education  \\\n",
              "0  Muhammad Talha  [{'university_name': 'National Textile Univers...   \n",
              "1  Muhammad Talha  [{'university_name': 'National Textile Univers...   \n",
              "\n",
              "                                          experience  \\\n",
              "0  [{'company_name': 'Not Found', 'n_years': '1 y...   \n",
              "1  [{'company_name': 'TransData', 'n_years': '1.5...   \n",
              "\n",
              "                                              skills employment_gaps  \\\n",
              "0  [Programming, Logical and Structured Thinking,...       Not Found   \n",
              "1  [Machine Learning, Data Analysis, Deep Learnin...            None   \n",
              "\n",
              "                                        contact_info  \\\n",
              "0  {'email': 'muhammadtalha1818@gmail.com', 'phon...   \n",
              "1  {'email': 'muhammadtalha1818@gmail.com', 'phon...   \n",
              "\n",
              "                                             summary  \\\n",
              "0                                          Not Found   \n",
              "1  Highly experienced in machine learning, deep l...   \n",
              "\n",
              "                                            metadata           label  \\\n",
              "0  {'distance': 0.7845, 'score': 56.04, 'source':...    Strong match   \n",
              "1  {'distance': 0.83, 'score': 54.64, 'source': '...  Moderate match   \n",
              "\n",
              "   match_score  total_experience  \n",
              "0        56.04               1.0  \n",
              "1        54.64               4.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bd2dfbec-3f4a-4c15-be98-10a4d91630a5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>education</th>\n",
              "      <th>experience</th>\n",
              "      <th>skills</th>\n",
              "      <th>employment_gaps</th>\n",
              "      <th>contact_info</th>\n",
              "      <th>summary</th>\n",
              "      <th>metadata</th>\n",
              "      <th>label</th>\n",
              "      <th>match_score</th>\n",
              "      <th>total_experience</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Muhammad Talha</td>\n",
              "      <td>[{'university_name': 'National Textile Univers...</td>\n",
              "      <td>[{'company_name': 'Not Found', 'n_years': '1 y...</td>\n",
              "      <td>[Programming, Logical and Structured Thinking,...</td>\n",
              "      <td>Not Found</td>\n",
              "      <td>{'email': 'muhammadtalha1818@gmail.com', 'phon...</td>\n",
              "      <td>Not Found</td>\n",
              "      <td>{'distance': 0.7845, 'score': 56.04, 'source':...</td>\n",
              "      <td>Strong match</td>\n",
              "      <td>56.04</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Muhammad Talha</td>\n",
              "      <td>[{'university_name': 'National Textile Univers...</td>\n",
              "      <td>[{'company_name': 'TransData', 'n_years': '1.5...</td>\n",
              "      <td>[Machine Learning, Data Analysis, Deep Learnin...</td>\n",
              "      <td>None</td>\n",
              "      <td>{'email': 'muhammadtalha1818@gmail.com', 'phon...</td>\n",
              "      <td>Highly experienced in machine learning, deep l...</td>\n",
              "      <td>{'distance': 0.83, 'score': 54.64, 'source': '...</td>\n",
              "      <td>Moderate match</td>\n",
              "      <td>54.64</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bd2dfbec-3f4a-4c15-be98-10a4d91630a5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bd2dfbec-3f4a-4c15-be98-10a4d91630a5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bd2dfbec-3f4a-4c15-be98-10a4d91630a5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f0065c96-fc95-470b-80bd-6d4378d05afc\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f0065c96-fc95-470b-80bd-6d4378d05afc')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f0065c96-fc95-470b-80bd-6d4378d05afc button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_14bc8a65-c08f-4ef6-836d-7cb63b940c1c\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_14bc8a65-c08f-4ef6-836d-7cb63b940c1c button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Muhammad Talha\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"education\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"experience\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"skills\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"employment_gaps\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Not Found\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"contact_info\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summary\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Highly experienced in machine learning, deep learning, and natural language processing (NLP), I am a passionate engineer and thriving analyst.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"metadata\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Moderate match\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"match_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9899494936611655,\n        \"min\": 54.64,\n        \"max\": 56.04,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          54.64\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_experience\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.1213203435596424,\n        \"min\": 1.0,\n        \"max\": 4.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          4.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "distance = 0.81\n",
        "similarity_score = 55.09 / 100  # normalize to 0â€“1 scale\n",
        "\n",
        "score = round(((1 - min(distance, 2)) * 0.6 + similarity_score * 0.4) * 100, 2)\n",
        "print(score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kd5hwrHV8AVq",
        "outputId": "5bbe7029-c98d-4358-d981-16ebbf887414"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33.44\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qQ3LpKcT-zUz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}